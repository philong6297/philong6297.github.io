<!doctype html><html lang=en><head><title>C++ Parallel STL is not yet for indiscriminate use · LongLP</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=color-scheme content="light dark"><meta name=author content="Phi-Long Le"><meta name=description content="1 Abstract Link to heading As of today, the hardware usually comes with multi-core architectures. People need to rely on something other than hardware vendors to improve single-core performance.
The hardware free-lunch has been over for about 15 years.
— Herb Sutter [1] —
In order to follow this evolution, one needs to ensure that software is performance-compatible with multi-core machines. The software industry started with a trend of incorporating concurrency in action."><meta name=keywords content="blog,developer,personal"><meta name=twitter:card content="summary"><meta name=twitter:title content="C++ Parallel STL is not yet for indiscriminate use"><meta name=twitter:description content="1 Abstract Link to heading As of today, the hardware usually comes with multi-core architectures. People need to rely on something other than hardware vendors to improve single-core performance.
The hardware free-lunch has been over for about 15 years.
— Herb Sutter [1] —
In order to follow this evolution, one needs to ensure that software is performance-compatible with multi-core machines. The software industry started with a trend of incorporating concurrency in action."><meta property="og:title" content="C++ Parallel STL is not yet for indiscriminate use"><meta property="og:description" content="1 Abstract Link to heading As of today, the hardware usually comes with multi-core architectures. People need to rely on something other than hardware vendors to improve single-core performance.
The hardware free-lunch has been over for about 15 years.
— Herb Sutter [1] —
In order to follow this evolution, one needs to ensure that software is performance-compatible with multi-core machines. The software industry started with a trend of incorporating concurrency in action."><meta property="og:type" content="article"><meta property="og:url" content="https://philong6297.github.io/posts/cpp_parallel_stl_is_not_yet_for_indiscriminate_use/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-02-20T00:00:00+00:00"><meta property="article:modified_time" content="2023-02-20T00:00:00+00:00"><link rel=canonical href=https://philong6297.github.io/posts/cpp_parallel_stl_is_not_yet_for_indiscriminate_use/><script class=longlp-local-custom-js src=/js/reorder_refs.min.fd945cc9618b50ec332e28d44d448c34f1c06746f690df382a29d4390f2f2818.js integrity="sha256-/ZRcyWGLUOwzLijUTUSMNPHAZ0b2kN84KinUOQ8vKBg="></script>
<link class=longlp-local-custom-css rel=stylesheet href=/css/custom.min.1778a9cebde69f3ae78153408588708a16bfcf81e7a7c2579eba3d38a3f3f7e5.css integrity="sha256-F3ipzr3mnzrngVNAhYhwiha/z4Hnp8JXnro9OKPz9+U=" crossorigin=anonymous media=screen><link rel=preload href="/fonts/forkawesome-webfont.woff2?v=1.2.0" as=font type=font/woff2 crossorigin><link rel=stylesheet href=/css/coder.min.36f76aaf39a14ecf5c3a3c6250dcaf06c238b3d8365d17d646f95cb1874e852b.css integrity="sha256-NvdqrzmhTs9cOjxiUNyvBsI4s9g2XRfWRvlcsYdOhSs=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/coder-dark.min.216e36d3eaf6f4cdfd67dc1200c49a8169e6478102977b3e9ac51a064c57054c.css integrity="sha256-IW420+r29M39Z9wSAMSagWnmR4ECl3s+msUaBkxXBUw=" crossorigin=anonymous media=screen><link rel=icon type=image/png href=/images/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/images/favicon-16x16.png sizes=16x16><link rel=apple-touch-icon href=/images/apple-touch-icon.png><link rel=apple-touch-icon sizes=180x180 href=/images/apple-touch-icon.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/images/safari-pinned-tab.svg color=#5bbad5><meta name=generator content="Hugo 0.110.0"></head><body class="preload-transitions colorscheme-auto"><div class=float-container><a id=dark-mode-toggle class=colorscheme-toggle><i class="fa fa-adjust fa-fw" aria-hidden=true></i></a></div><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=/>LongLP</a>
<input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=/posts/>Blog</a></li><li class=navigation-item><a class=navigation-link href=/about/>About</a></li></ul></section></nav><div class=content><section class="container post"><article><header><div class=post-title><h1 class=title><a class=title-link href=https://philong6297.github.io/posts/cpp_parallel_stl_is_not_yet_for_indiscriminate_use/>C++ Parallel STL is not yet for indiscriminate use</a></h1></div><div class=post-meta><div class=date><span class=posted-on><i class="fa fa-calendar" aria-hidden=true></i>
<time datetime=2023-02-20T00:00:00Z>February 20, 2023</time></span>
<span class=reading-time><i class="fa fa-clock-o" aria-hidden=true></i>
15-minute read</span></div><div class=tags><i class="fa fa-tag" aria-hidden=true></i>
<span class=tag><a href=/tags/cpp/>cpp</a></span></div></div></header><div class=post-content><h1>Table Of Contents</h1><nav id=TableOfContents><ul><li><a href=#1-abstract>1 Abstract</a></li><li><a href=#2-introduction>2 Introduction</a></li><li><a href=#3-difficulty-in-current-c-parallel-algorithms-design>3 Difficulty in current C++ Parallel Algorithms design</a><ul><li><a href=#31-no-concurrency-awareness>3.1 No Concurrency awareness</a></li><li><a href=#32-not-yet-completely-production-ready>3.2 Not yet completely production-ready</a></li><li><a href=#33-combining-stl-algorithms-introduces-sequential-behavior>3.3 Combining STL algorithms introduces sequential behavior</a></li><li><a href=#34-small-datasets-are-not-suitable-for-parallelization>3.4 Small datasets are not suitable for parallelization</a></li><li><a href=#35-stl-algorithms-is-not-tunning-friendly>3.5 STL Algorithms is not tunning-friendly</a></li><li><a href=#36-compile-time-overhead>3.6 Compile time overhead</a></li></ul></li><li><a href=#4-conclusion>4 Conclusion</a></li><li><a href=#5-appendix>5 Appendix</a></li><li><a href=#6-references>6 References</a></li></ul></nav><h1 id=1-abstract>1 Abstract
<a class=heading-link href=#1-abstract><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h1><p>As of today, the hardware usually comes with multi-core architectures.
People need to rely on something other than hardware vendors to improve
single-core performance.</p><blockquote><p>The hardware free-lunch has been over for about 15 years.</p><p>— Herb Sutter <a href=#ref-Sutter05>[1]</a> —</p></blockquote><p>In order to follow this evolution, one needs to ensure that software is
performance-compatible with multi-core machines. The software industry
started with a trend of incorporating concurrency in action. As
expected, ISO C++ has also started providing high-level abstractions for
expressing parallelism, moving beyond simple threads and synchronization
primitives: In 2017, the C++ standard introduced the so-called parallel
algorithms. In essence, this feature offers parallel versions of the
existing STL algorithms.</p><p>This article aims to demonstrate the author’s subjective opinion
on the current status of <em><strong>C++ Parallel Algorithms</strong></em> <sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> (as they
were introduced in C++17 and are currently present in C++20). Although
adding parallel versions to some STL algorithms is a reasonable
improvement, the author disputes that this is not such a significant
advancement as one might think.</p><h1 id=2-introduction>2 Introduction
<a class=heading-link href=#2-introduction><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h1><p>Given a context where there is a need to parallelize the following
<em><strong>transform</strong></em> algorithm:</p><div class=highlight><div style=color:#abb2bf;background-color:#282c34;-moz-tab-size:2;-o-tab-size:2;tab-size:2><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#abb2bf;background-color:#282c34;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#55595f">1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#55595f">2
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#55595f">3
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#55595f">4
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#abb2bf;background-color:#282c34;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#e06c75>std</span><span style=color:#56b6c2>::</span><span style=color:#e06c75>transform</span>(<span style=color:#e06c75>in</span>.<span style=color:#e06c75>begin</span>(), <span style=color:#e06c75>in</span>.<span style=color:#e06c75>end</span>(), <span style=color:#7f848e>// input range
</span></span></span><span style=display:flex><span><span style=color:#7f848e></span>               <span style=color:#e06c75>out</span>.<span style=color:#e06c75>begin</span>(),          <span style=color:#7f848e>// output range
</span></span></span><span style=display:flex><span><span style=color:#7f848e></span>               <span style=color:#e06c75>ftor</span>                  <span style=color:#7f848e>// transform fun
</span></span></span><span style=display:flex><span><span style=color:#7f848e></span>);
</span></span></code></pre></td></tr></table></div></div><p>Since C++ 17, one could follow the <code>std::transform</code> interface and use it
as below:</p><div class=highlight><div style=color:#abb2bf;background-color:#282c34;-moz-tab-size:2;-o-tab-size:2;tab-size:2><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#abb2bf;background-color:#282c34;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#55595f">1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#55595f">2
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#55595f">3
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#55595f">4
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#55595f">5
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#abb2bf;background-color:#282c34;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#e06c75>std</span><span style=color:#56b6c2>::</span><span style=color:#e06c75>transform</span>(<span style=color:#e06c75>std</span><span style=color:#56b6c2>::</span><span style=color:#e06c75>execution</span><span style=color:#56b6c2>::</span><span style=color:#e06c75>par_unseq</span>, <span style=color:#7f848e>// parallel policy
</span></span></span><span style=display:flex><span><span style=color:#7f848e></span>               <span style=color:#e06c75>in</span>.<span style=color:#e06c75>begin</span>(), <span style=color:#e06c75>in</span>.<span style=color:#e06c75>end</span>(),      <span style=color:#7f848e>// input range
</span></span></span><span style=display:flex><span><span style=color:#7f848e></span>               <span style=color:#e06c75>out</span>.<span style=color:#e06c75>begin</span>(),               <span style=color:#7f848e>// output range
</span></span></span><span style=display:flex><span><span style=color:#7f848e></span>               <span style=color:#e06c75>ftor</span>                       <span style=color:#7f848e>// transform fun
</span></span></span><span style=display:flex><span><span style=color:#7f848e></span>);
</span></span></code></pre></td></tr></table></div></div><p>The difference versus the traditional invocation of <code>transform</code> is the
first parameter for setting up parallel policy hints. This parameter
tells the algorithm to use parallelization and vectorization in the
given case.</p><p>The official term for this param is <em><strong>Execution Policy</strong></em> <sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup> <sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup>. It
suggests the type of execution for the algorithm. As of current ISO C++
(C++ 23), there are four parallel policies:</p><ul><li><code>seq</code><br>An instance of <code>std::sequenced_policy</code>. It uses the sequential version
of the algorithm. The “classic” version of STL algorithms
(no Execution Policy param) is also supposed to be the same as this
one.</li><li><code>par</code><br>An instance of <code>std::parallel_policy</code>. The algorithm is allowed to
parallelize but disallowed to vectorize.</li><li><code>par_unseq</code><br>Instance of <code>std::parallel_unsequenced_policy</code>. The algorithm can be
both parallelized and vectorized.</li><li><code>unseq</code><br>Instance of <code>std::unsequenced_policy</code>. The algorithm is allowed to
vectorize but disallowed to parallelize.</li></ul><p>Therefore, the parallelizing effort is minimal. One could specify the
parallel policy to transform an existing STL algorithm into a parallel
(or vectorized) version.</p><p>However, STL algorithm implementations only considered the Execution
Policy as a hint or the maximum parallelization/vectorization level
allowed. They can ignore it and fall back to the serial execution
entirely.</p><p>Currently, most STL algorithms can take the Execution Policy parameter
as an instruction to run in parallel. Several new algorithms were added
to overcome the constraints of existing algorithms that forbid
parallelizing them or that there are better ways to express some
parallel algorithms (<code>reduce</code>, <code>exclusive_scan</code>, <code>inclusive_scan</code>,
<code>transform_reduce</code>, <code>transform_exclusive_scan</code>,
<code>transform_inclusive_scane</code>).</p><p>This article primarily focuses on parallel execution (<code>par</code> policy),
which aims to utilize all the available cores to increase efficiency.
Nonetheless, the author briefly touches on vectorization (<code>unseq</code>
policy) towards the end of the article <sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup>.</p><h1 id=3-difficulty-in-current-c-parallel-algorithms-design>3 Difficulty in current C++ Parallel Algorithms design
<a class=heading-link href=#3-difficulty-in-current-c-parallel-algorithms-design><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h1><h2 id=31-no-concurrency-awareness>3.1 No Concurrency awareness
<a class=heading-link href=#31-no-concurrency-awareness><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>The first thing to notice is that it is straightforward to adapt
existing algorithms and make them parallel. This improvement explains
the success of parallel algorithms (at least at the perception level).</p><p>Despite the C++ committee not intending to solve the concurrency problem
with STL Parallel (they wanted to solve local efficiency problems), it
also has a negative effect from a didactical point of view <sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup>. C++
parallel algorithms have not allowed a global concurrency design. It
allows only local optimizations by making some algorithm calls
parallelizable. It is reasonable, for limited domains, to focus more on
efficiency than design, but that is typically different with
concurrency. One must pay attention to the design to get suboptimal
efficiency. In other words, multi-core efficiency is a global
optimization problem, not a local one. Considering this, the C++ users
might misunderstand that they do not need to pay attention to
concurrency issues; One can count on C++ STL to magically resolve them.</p><p>This problem is concluded to be the same problem that initially led
people to insufficient concurrency design. Instead of recognizing that
concurrency needs an entirely new type of design, the C++ standard tried
to apply sequential thinking by adding the ability to run on multiple
threads <sup id=fnref:6><a href=#fn:6 class=footnote-ref role=doc-noteref>6</a></sup>. Dropping the old ways of writing software and adopting a
new paradigm is necessary for proper concurrency.</p><h2 id=32-not-yet-completely-production-ready>3.2 Not yet completely production-ready
<a class=heading-link href=#32-not-yet-completely-production-ready><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><blockquote><p>the overall performance improvement gained by optimizing a single part
of a system is limited by the fraction of time that the improved part
is actually used</p><p>– Martin Reddy <a href=#ref-Martin2011>[11]</a> –</p></blockquote><p>Based on Amdahl’s law <a href=#ref-Amdahl1967>[12]</a>, <a href=#ref-David1985>[13]</a>, one needs to
have a significant part of the parallelizable code to have speed
improvements from parallelism. In the case of Parallel STL, one needs to
have considerable parts of the application using such algorithms. In
other words, the vast majority of the time must be spent on STL
algorithms to have relevant performance benefits.</p><p>However, not every program consists just of STL algorithm calls.
Currently, many programs have flows that are tough to reduce to STL
algorithms (if it is even possible). These applications can only expose
control flow concurrency, making them unsuitable for using parallel
algorithms. Imagine a context where the application is doing graph
processing. In most cases, no STL algorithms are ready yet to be used.</p><h2 id=33-combining-stl-algorithms-introduces-sequential-behavior>3.3 Combining STL algorithms introduces sequential behavior
<a class=heading-link href=#33-combining-stl-algorithms-introduces-sequential-behavior><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>Suppose a context where one needs to call multiple STL algorithms. If
the algorithms were to interact, then they need to be called serially:</p><div class=figure style=text-align:center><img src=images/stl-algorithm-flow.png alt="STL Algorithms Flow Illustration." width=100%><p class=caption>STL Algorithms Flow Illustration.</p></div><p>In the above figure, three flow parts are bound to execute sequentially:
before the first algorithm, between the algorithm calls, and at the end
of the second algorithm. Moreover, no matter how exemplary the
implementation is, the synchronizing and starting tasks need additional
time. Thus, according to Amdahl’s law <a href=#ref-Amdahl1967>[12]</a>,
<a href=#ref-David1985>[13]</a>, this puts an upper limit on performance improvement.</p><p>Nevertheless, whenever the algorithm ends, it must wait for all the
threads to finish executing, which reduces the machine’s
parallelism capacity. This behavior results from the fact that the work
cannot perfectly distribute between threads; several threads process
more than others.</p><p>To counter this problem, one could do one or more of the following:</p><ul><li>Start algorithms from multiple threads</li><li>Ensure that algorithms have continuations or pipelining, avoiding
serially calling algorithms</li><li>Tune the parallel algorithms to ensure the work’s dividing.</li></ul><p>The first item can be possible outside parallel STL without direct
support. However, the current design of the C++ standard library does
not allow one to implement any of the latter.</p><h2 id=34-small-datasets-are-not-suitable-for-parallelization>3.4 Small datasets are not suitable for parallelization
<a class=heading-link href=#34-small-datasets-are-not-suitable-for-parallelization><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>To make it worthwhile to parallelize an algorithm, the execution time of
the algorithm needs to be significant <sup id=fnref:7><a href=#fn:7 class=footnote-ref role=doc-noteref>7</a></sup>. Teodorescu <a href=#ref-Teodorescu20a>[14]</a> has
refocused Amdahl’s Law <a href=#ref-Amdahl1967>[12]</a>, <a href=#ref-David1985>[13]</a> and
suggested that the algorithm needs to take more than 100 milliseconds to
be beneficial from parallelizing. Other optimization opportunities could
be better helpful if this is not the case.</p><p>Such algorithms (which have long execution times) either have a
sufficiently large number of elements (e.g., millions of elements) in
the collection, or the operation given to the algorithm needs to take a
long time. While the latter can be prevalent in many applications, the
former (considerable elements) is typically unpopular.</p><p>To give an order of magnitude for <em>numerous elements</em>, Bartlomiej
<a href=#ref-Filipek17b>[5]</a> benchmarked two experiments on a decent high-performance
machine. The first benchmark is a simple transform operation (the
functor doubling the value received). For 100k elements, the execution
times decrease from 0.524 to 0.389 seconds. A 1.3x improvement for six
cores machine is not worth parallelizing. After this test, Bartlomiej
writes <a href=#ref-Filipek17b>[5]</a>:</p><blockquote><p>As you see on the faster machine, you need like 1 million elements to
start seeing some performance gains. On the other hand, on my
notebook, all parallel implementations were slower.</p></blockquote><p>The last experiment is a real-world problem: Computing the Fresnel
transformation on 3D vectors. The parallelization improvement result is
sufficient, an approximate 6x improvement (from 1.697 seconds to 0.283
seconds) for 100k elements. Although these tests are biased, they still
present a rough observation: <strong>One needs a significant number of
elements (100k) for the performance improvement to be hundreds of
milliseconds</strong>.</p><p>Consider other benchmarks from the parallel algorithms implementor of
Microsoft Visual Studio’s standard library, Billy <a href=#ref-ONeal18>[6]</a>.
His article illustrates several benchmarks for sorting algorithms. The
experiment contexts use 1 million elements, resulting in less than 100
milliseconds.</p><p>To conclude, to see significant performance improvements from
parallelizing STL algorithms, containers with a rough order of magnitude
of 1 million elements must be made. This condition only happens
sometimes.</p><h2 id=35-stl-algorithms-is-not-tunning-friendly>3.5 STL Algorithms is not tunning-friendly
<a class=heading-link href=#35-stl-algorithms-is-not-tunning-friendly><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>This problem affects all the STL algorithms. Thus, the author takes the
<code>sort</code> algorithm as a running example. For a few elements, sorting is
faster with a linear algorithm than with a parallel one.
Production-ready algorithms typically have a threshold: if the number of
elements is below this point, the algorithm calls the serial version.
The cutoff point varies on algorithm implementations. Intel
OneTBB’s <code>parallel_sort</code> and GNU <code>libstdc++</code> set this value to
<code>500</code> <a href=#ref-IntelOneTBB>[15]</a>:</p><div class=highlight><div style=color:#abb2bf;background-color:#282c34;-moz-tab-size:2;-o-tab-size:2;tab-size:2><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#abb2bf;background-color:#282c34;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#55595f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#55595f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#55595f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#55595f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#55595f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#55595f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#55595f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#55595f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#55595f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#55595f">10
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#55595f">11
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#55595f">12
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#55595f">13
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#55595f">14
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#55595f">15
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#55595f">16
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#55595f">17
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#55595f">18
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#abb2bf;background-color:#282c34;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#7f848e>//! Sorts the data in [begin,end) using the given comparator
</span></span></span><span style=display:flex><span><span style=color:#7f848e></span><span style=color:#7f848e>/** The compare function object is used for all comparisons between elements during sorting.
</span></span></span><span style=display:flex><span><span style=color:#7f848e>    The compare object must define a bool operator() function.
</span></span></span><span style=display:flex><span><span style=color:#7f848e>    @ingroup algorithms **/</span>
</span></span><span style=display:flex><span><span style=color:#c678dd>template</span><span style=color:#56b6c2>&lt;</span><span style=color:#c678dd>typename</span> <span style=color:#e06c75>RandomAccessIterator</span>, <span style=color:#c678dd>typename</span> <span style=color:#e06c75>Compare</span><span style=color:#56b6c2>&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#e06c75>__TBB_requires</span>(<span style=color:#e06c75>std</span><span style=color:#56b6c2>::</span><span style=color:#e06c75>random_access_iterator</span><span style=color:#56b6c2>&lt;</span><span style=color:#e06c75>RandomAccessIterator</span><span style=color:#56b6c2>&gt;</span> <span style=color:#56b6c2>&amp;&amp;</span>
</span></span><span style=display:flex><span>                   <span style=color:#e06c75>compare</span><span style=color:#56b6c2>&lt;</span><span style=color:#e06c75>Compare</span>, <span style=color:#e06c75>RandomAccessIterator</span><span style=color:#56b6c2>&gt;</span> <span style=color:#56b6c2>&amp;&amp;</span>
</span></span><span style=display:flex><span>                   <span style=color:#e06c75>std</span><span style=color:#56b6c2>::</span><span style=color:#e06c75>movable</span><span style=color:#56b6c2>&lt;</span><span style=color:#e06c75>iter_value_type</span><span style=color:#56b6c2>&lt;</span><span style=color:#e06c75>RandomAccessIterator</span><span style=color:#56b6c2>&gt;&gt;</span>)
</span></span><span style=display:flex><span><span style=color:#e5c07b>void</span> <span style=color:#e06c75>parallel_sort</span>( <span style=color:#e06c75>RandomAccessIterator</span> <span style=color:#e06c75>begin</span>, <span style=color:#e06c75>RandomAccessIterator</span> <span style=color:#e06c75>end</span>, <span style=color:#c678dd>const</span> <span style=color:#e06c75>Compare</span><span style=color:#56b6c2>&amp;</span> <span style=color:#e06c75>comp</span> ) {
</span></span><span style=display:flex><span>    <span style=color:#c678dd>constexpr</span> <span style=color:#e5c07b>int</span> <span style=color:#e06c75>min_parallel_size</span> <span style=color:#56b6c2>=</span> <span style=color:#d19a66>500</span>;
</span></span><span style=display:flex><span>    <span style=color:#c678dd>if</span>( <span style=color:#e06c75>end</span> <span style=color:#56b6c2>&gt;</span> <span style=color:#e06c75>begin</span> ) {
</span></span><span style=display:flex><span>        <span style=color:#c678dd>if</span>( <span style=color:#e06c75>end</span> <span style=color:#56b6c2>-</span> <span style=color:#e06c75>begin</span> <span style=color:#56b6c2>&lt;</span> <span style=color:#e06c75>min_parallel_size</span> ) {
</span></span><span style=display:flex><span>            <span style=color:#e06c75>std</span><span style=color:#56b6c2>::</span><span style=color:#e06c75>sort</span>(<span style=color:#e06c75>begin</span>, <span style=color:#e06c75>end</span>, <span style=color:#e06c75>comp</span>);
</span></span><span style=display:flex><span>        } <span style=color:#c678dd>else</span> {
</span></span><span style=display:flex><span>            <span style=color:#e06c75>parallel_quick_sort</span>(<span style=color:#e06c75>begin</span>, <span style=color:#e06c75>end</span>, <span style=color:#e06c75>comp</span>);
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></td></tr></table></div></div><p>The value <code>500</code> is well-analyzed with primitive type experiments
(string, integers, floating-points) by STL vendors before being set as
the threshold. However, one size does not fit all; this cutoff point
must be different to sort some complex objects. Unfortunately, <strong>the C++
standard only aims to support the general purpose and does not allow any
customizing of the algorithms</strong>. This leads to suboptimal performance.</p><p>Similarly, given a simple <code>for_each</code> operation, if the algorithm needs
to call a heavy function, it is reasonable to have each element mapped
into a task. However, if the transformation is simple (i.e., an
arithmetic operation), creating one task per element is not ideal for
performance. Algorithms may need tuning to adjust different input
patterns.</p><p>Similarly, let’s assume a simple <code>for_each</code> operation. For some
cases, if the algorithm needs to call a heavy function, it’s ok to
have each element mapped into a task. On the other hand, if the
transformation is simple (i.e., an arithmetic operation) then, creating
one task per element will be bad for performance. Thus, algorithms may
need tuning to accommodate different input patterns.</p><p>Concore library <a href=#ref-concore>[16]</a> showing how one can set hints to parallel
algorithms:</p><div class=highlight><div style=color:#abb2bf;background-color:#282c34;-moz-tab-size:2;-o-tab-size:2;tab-size:2><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#abb2bf;background-color:#282c34;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#55595f">1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#55595f">2
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#55595f">3
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#55595f">4
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#55595f">5
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#abb2bf;background-color:#282c34;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#e06c75>concore</span><span style=color:#56b6c2>::</span><span style=color:#e06c75>partition_hints</span> <span style=color:#e06c75>hints</span>;
</span></span><span style=display:flex><span><span style=color:#e06c75>hints</span>.<span style=color:#e06c75>granularity_</span> <span style=color:#56b6c2>=</span> <span style=color:#d19a66>100</span>;
</span></span><span style=display:flex><span><span style=color:#7f848e>// cannot process less than 100 elements in
</span></span></span><span style=display:flex><span><span style=color:#7f848e>// a single task
</span></span></span><span style=display:flex><span><span style=color:#7f848e></span><span style=color:#e06c75>concore</span><span style=color:#56b6c2>::</span><span style=color:#e06c75>conc_for</span>(<span style=color:#e06c75>input</span>.<span style=color:#e06c75>begin</span>(), <span style=color:#e06c75>input</span>.<span style=color:#e06c75>end</span>(), <span style=color:#e06c75>functor</span>, <span style=color:#e06c75>hints</span>);
</span></span></code></pre></td></tr></table></div></div><h2 id=36-compile-time-overhead>3.6 Compile time overhead
<a class=heading-link href=#36-compile-time-overhead><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>C++ STL is heavily templatized and needs to be implemented in header
files. Even so, implementing parallel algorithms is far more complicated
than serial versions and adds significant compile-time overhead <sup id=fnref:8><a href=#fn:8 class=footnote-ref role=doc-noteref>8</a></sup>.</p><p>People could not take this problem lightly since it takes more time to
compile C++ programs. Especially when applying Test-Driven-Development
in the project, compilation cycles take forever to compile.</p><p>Fortunately, there are a few tricks that both implementers can employ to
save part of this problem. Jorg introduced several techniques to reduce
compile time costs in CppCon 2019 <a href=#ref-Jorg19>[18]</a>. For example, GCC will
not compile the parallel versions of the library if <code>&lt;execution></code> is not
included <a href=#ref-Rodgers18>[17]</a>.</p><h1 id=4-conclusion>4 Conclusion
<a class=heading-link href=#4-conclusion><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h1><p>C++ parallel STL brings parallelization and vectorization to standard
algorithms without requiring much effort from the user. However, the
author considered this feature under-expected and needs better support.</p><p>Firstly, moving to multi-core programming requires a global concurrency
design. C++ parallel algorithms do not offer any support for this.
Moreover, the standard (accidentally) misguide to C++ users that
parallelism can be easily achieved without concurrent understanding.</p><p>Secondly, besides the high-level concurrency design issue, the standard
parallel library also has limitations at the low level. As applications
have more than just algorithms, using standard C++ parallel algorithms
is insufficient to achieve good speedups for most applications. The
article covers several problems related to lower-level performance
issues:</p><ul><li>STL algorithms are serialized.</li><li>Typically, Small datasets are unsuitable for parallelization</li><li>Impossibility of tuning the algorithms.</li><li>Compile time overhead.</li></ul><p>It is true that it’s easy for a user to quickly change the policy
of the STL algorithms and maybe get some performance benefits. But my
focus in this article is on the empty half of the glass. I’m
arguing that the benefits are not as big as one could obtain with a
proper concurrency design. In some limited cases (i.e., many elements,
or functors that are too complex) one might get some speedups for
one’s algorithms. But even in these cases, the costs of spiking
into using multiple cores may have an overall negative performance
costs.</p><p>All these make C++ parallel algorithms less of a great addition to the
concurrency frameworks. The author agrees that they are needed, but it
is still insufficient. The basic executor concept would have been a
better complement to the standard. Unfortunately, the executors did not
make it to C++ 23. So, let people wait to see what the future will
reserve.</p><h1 id=5-appendix>5 Appendix
<a class=heading-link href=#5-appendix><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h1><h1 id=6-references>6 References
<a class=heading-link href=#6-references><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h1><div id=refs class="references csl-bib-body"><div id=ref-Sutter05 class=csl-entry><p><span class=csl-left-margin>[1] </span><span class=csl-right-inline>H. Sutter, “The free lunch is over a
fundamental turn toward concurrency in software,” 2005.</span></p></div><div id=ref-iso-cpp-20 class=csl-entry><p><span class=csl-left-margin>[2] </span><span class=csl-right-inline>“<span class=nocase>Programming
languages - C++</span>,” International Organization for
Standardization; ISO/IEC 14882:2020, International Standard, Dec.
2020.Available: <a href=https://www.iso.org/standard/79358.html>https://www.iso.org/standard/79358.html</a></span></p></div><div id=ref-Lelbach16 class=csl-entry><p><span class=csl-left-margin>[3] </span><span class=csl-right-inline>B. A. Lelbach, “<span class=nocase>C++
Parallel Algorithms and Beyond</span>.” CppCon 2016 conference,
2016.Available: <a href="https://www.youtube.com/watch?v=UJrmee7o68A">https://www.youtube.com/watch?v=UJrmee7o68A</a></span></p></div><div id=ref-Filipek17a class=csl-entry><p><span class=csl-left-margin>[4] </span><span class=csl-right-inline>B. Filipek, “<span class=nocase>C++17
in details: Parallel Algorithms</span>.” C++ Stories, blog, 2017
[Online].Available:
<a href=https://www.cppstories.com/2017/08/cpp17-details-parallel/>https://www.cppstories.com/2017/08/cpp17-details-parallel/</a></span></p></div><div id=ref-Filipek17b class=csl-entry><p><span class=csl-left-margin>[5] </span><span class=csl-right-inline>B. Filipek, “<span class=nocase>The
Amazing Performance of C++17 Parallel Algorithms, is it
Possible?</span>” C++ Stories, blog, 2018 [Online].Available:
<a href=https://www.cppstories.com/2018/11/parallel-alg-perf/>https://www.cppstories.com/2018/11/parallel-alg-perf/</a></span></p></div><div id=ref-ONeal18 class=csl-entry><p><span class=csl-left-margin>[6] </span><span class=csl-right-inline>B. O’Neal, “<span class=nocase>Using C++17 Parallel Algorithms for Better
Performance</span>.” C++ Team Blog, blog, 2018
[Online].Available:
<a href=https://devblogs.microsoft.com/cppblog/using-c17-parallel-algorithms-for-better-performance/>https://devblogs.microsoft.com/cppblog/using-c17-parallel-algorithms-for-better-performance/</a></span></p></div><div id=ref-Parent16 class=csl-entry><p><span class=csl-left-margin>[7] </span><span class=csl-right-inline>S. Parent, “Better Code:
Concurrency.” code::dive 2016 conference, 2016.Available:
<a href="https://www.youtube.com/watch?v=QIHy8pXbneI">https://www.youtube.com/watch?v=QIHy8pXbneI</a></span></p></div><div id=ref-Pike13 class=csl-entry><p><span class=csl-left-margin>[8] </span><span class=csl-right-inline>R. Pike, “Concurrency Is Not
Parallelism.” Heroku’s Waza conference, 2012.Available:
<a href=https://go.dev/talks/2012/waza.slide#2>https://go.dev/talks/2012/waza.slide#2</a></span></p></div><div id=ref-Teodorescu20c class=csl-entry><p><span class=csl-left-margin>[9] </span><span class=csl-right-inline>L. R. Teodorescu, “Concurrency Design
Patterns,” <em>Overload</em>, vol. 159, pp. 12–18, 2020
[Online],Available:
<a href="https://accu.org/journals/overload/28/159/overload159.pdf#page=14">https://accu.org/journals/overload/28/159/overload159.pdf#page=14</a></span></p></div><div id=ref-Henney17 class=csl-entry><p><span class=csl-left-margin>[10] </span><span class=csl-right-inline>K. Henney, “<span class=nocase>Thinking
Outside the Synchronisation Quadrant</span>.” ACCU 2017
conference, 2017.Available:
<a href="https://www.youtube.com/watch?v=UJrmee7o68A">https://www.youtube.com/watch?v=UJrmee7o68A</a></span></p></div><div id=ref-Martin2011 class=csl-entry><p><span class=csl-left-margin>[11] </span><span class=csl-right-inline>M. Reddy, “Chapter 7 -
Performance,” in <em><span class=nocase>API Design for C++</span></em>,
M. Reddy, Ed. Boston: Morgan Kaufmann, 2011, pp. 209–240. doi:
<a href=https://doi.org/10.1016/B978-0-12-385003-4.00007-5>https://doi.org/10.1016/B978-0-12-385003-4.00007-5</a>.</span></p></div><div id=ref-Amdahl1967 class=csl-entry><p><span class=csl-left-margin>[12] </span><span class=csl-right-inline>G. M. Amdahl, “Validity of the single
processor approach to achieving large scale computing
capabilities,” in <em>Proceedings of the april 18-20, 1967, spring
joint computer conference</em>, 1967, pp. 483–485. doi:
<a href=https://doi.org/10.1145/1465482.1465560>10.1145/1465482.1465560</a>.</span></p></div><div id=ref-David1985 class=csl-entry><p><span class=csl-left-margin>[13] </span><span class=csl-right-inline>D. P. Rodgers, “Improvements in
multiprocessor system design,” <em>SIGARCH Comput. Archit. News</em>,
vol. 13, no. 3, pp. 225–231, Jun. 1985, doi:
<a href=https://doi.org/10.1145/327070.327215>10.1145/327070.327215</a>.</span></p></div><div id=ref-Teodorescu20a class=csl-entry><p><span class=csl-left-margin>[14] </span><span class=csl-right-inline>L. R. Teodorescu, “<span class=nocase>Refocusing Amdahl’s Law</span>,” <em>Overload</em>,
vol. 157, pp. 5–10, 2020 [Online],Available:
<a href="https://accu.org/journals/overload/28/157/overload157.pdf#page=7">https://accu.org/journals/overload/28/157/overload157.pdf#page=7</a></span></p></div><div id=ref-IntelOneTBB class=csl-entry><p><span class=csl-left-margin>[15] </span><span class=csl-right-inline>“<span class=nocase>oneAPI Threading
Building Blocks (oneTBB)</span>,” <em>GitHub repository</em>. Intel
Corporation;
<a href=https://github.com/oneapi-src/oneTBB/blob/master/include/oneapi/tbb/parallel_sort.h;>https://github.com/oneapi-src/oneTBB/blob/master/include/oneapi/tbb/parallel_sort.h;</a>
GitHub, 2023 [Online].</span></p></div><div id=ref-concore class=csl-entry><p><span class=csl-left-margin>[16] </span><span class=csl-right-inline>L. R. Teodorescu, <em><span class=nocase>Concore
library</span></em>. ver. 0.5, 2021 [Online].Available:
<a href=https://github.com/lucteo/concore>https://github.com/lucteo/concore</a></span></p></div><div id=ref-Rodgers18 class=csl-entry><p><span class=csl-left-margin>[17] </span><span class=csl-right-inline>T. Rodgers, “<span class=nocase>Bringing C++ 17 Parallel Algorithms to a Standard Library
Near You</span>.” CppCon 2018 conference, 2018.Available:
<a href="https://www.youtube.com/watch?v=-KT8gaojHUU">https://www.youtube.com/watch?v=-KT8gaojHUU</a></span></p></div><div id=ref-Jorg19 class=csl-entry><p><span class=csl-left-margin>[18] </span><span class=csl-right-inline>J. Brown, “<span class=nocase>Reducing
Template Compilation Overhead, Using C++11, 14, 17, and
20</span>.” CppCon 2019 conference, 2019.Available:
<a href="https://www.youtube.com/watch?v=TyiiNVA1syk">https://www.youtube.com/watch?v=TyiiNVA1syk</a></span></p></div></div><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>The author intercharges <em><strong>C++ Parallel STL</strong></em> term with <em><strong>C++
parallel algorithms</strong></em>.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>According to ISO C++ 20 <a href=#ref-iso-cpp-20>[2]</a>:</p><ul><li><code>std::sequenced_policy</code></li></ul><blockquote><p>The execution policy type used as a unique type to disambiguate
parallel algorithm overloading and require that a parallel
algorithm’s execution may not be parallelized. The
invocations of element access functions in parallel algorithms
invoked with this policy (usually specified as
<code>std::execution::seq</code>) are indeterminately sequenced in the
calling thread.</p></blockquote><ul><li><code>std::parallel_policy</code></li></ul><blockquote><p>The execution policy type used as a unique type to disambiguate
parallel algorithm overloading and indicate that a parallel
algorithm’s execution may be parallelized. The invocations
of element access functions in parallel algorithms invoked with
this policy (usually specified as <code>std::execution::par</code>) are
permitted to execute in either the invoking thread or in a thread
implicitly created by the library to support parallel algorithm
execution. Any such invocations executing in the same thread are
indeterminately sequenced with respect to each other.</p></blockquote><ul><li><code>std::parallel_unsequenced_policy</code></li></ul><blockquote><p>The execution policy type used as a unique type to disambiguate
parallel algorithm overloading and indicate that a parallel
algorithm’s execution may be parallelized, vectorized, or
migrated across threads (such as by a parent-stealing scheduler).
The invocations of element access functions in parallel algorithms
invoked with this policy are permitted to execute in an unordered
fashion in unspecified threads, and unsequenced with respect to
one another within each thread.</p></blockquote><ul><li><code>std::unsequenced_policy</code></li></ul><blockquote><p>The execution policy type used as a unique type to disambiguate
parallel algorithm overloading and indicate that a parallel
algorithm’s execution may be vectorized, e.g., executed on a
single thread using instructions that operate on multiple data
items.</p></blockquote>&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></li><li id=fn:3><p><a href=#ref-Lelbach16>[3]</a>–<a href=#ref-ONeal18>[6]</a> provided comprehensive introduction
and explanation of C++ parallel algorithms.&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4><p>In order to efficiently use vectorization without global
parallelism design, one typically must focus on the local
computations. The local-focus approach is perfect for applying
vectorization at the STL algorithms level: It can unlock a more
significant portion of the computation power available on modern
hardware <a href=#ref-Parent16>[7]</a>.&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:5><p>The author discusses parallelism, not concurrency. The distinction
is well-explained by Pike and Teodorescu <a href=#ref-Pike13>[8]</a>, <a href=#ref-Teodorescu20c>[9]</a>. In
short, Concurrency is a design concern, while parallelism is a
run-time efficiency concern.&#160;<a href=#fnref:5 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:6><p>This article supports Henney’s well-discussion on the
synchronization quadrant <a href=#ref-Henney17>[10]</a>.&#160;<a href=#fnref:6 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:7><blockquote><p>Please excuse my over-generalisation, but it doesn’t seem
too rewarding to try to parallelize a 100 millisecond algorithm.
Obtaining a linear speedup on a 6-core machine would save 83.3
milliseconds on the completion time, and will fully utilise all
the cores.</p><p>– Lucian Radu Teodorescu <a href=#ref-Teodorescu20a>[14]</a> –</p></blockquote>&#160;<a href=#fnref:7 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></li><li id=fn:8><p>Rodgers provided some metrics about this problem in CppCon 2018
<a href=#ref-Rodgers18>[17]</a>&#160;<a href=#fnref:8 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><footer></footer></article><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css integrity=sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0 crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js integrity=sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4 crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}]})'></script></section></div><footer class=footer><section class=container>©
2021 -
2023
Phi-Long Le</section></footer></main><script src=/js/coder.min.27afce394fb6284f521b3fbc9f6a8326342333c3092267f3944d770489876fed.js integrity="sha256-J6/OOU+2KE9SGz+8n2qDJjQjM8MJImfzlE13BImHb+0="></script></body></html>